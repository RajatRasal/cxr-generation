{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6a3348c0-3a69-4e23-84b8-726936574523",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'health_multimodal'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 11\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mIPython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdisplay\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m display\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mIPython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdisplay\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Markdown\n\u001b[0;32m---> 11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mhealth_multimodal\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcommon\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mvisualization\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m plot_phrase_grounding_similarity_map\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mhealth_multimodal\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtext\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m get_bert_inference\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mhealth_multimodal\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtext\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BertEncoderType\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'health_multimodal'"
     ]
    }
   ],
   "source": [
    "from typing import List\n",
    "from typing import Tuple\n",
    "\n",
    "import tempfile\n",
    "from pathlib import Path\n",
    "\n",
    "import torch\n",
    "from IPython.display import display\n",
    "from IPython.display import Markdown\n",
    "\n",
    "from health_multimodal.common.visualization import plot_phrase_grounding_similarity_map\n",
    "from health_multimodal.text import get_bert_inference\n",
    "from health_multimodal.text.utils import BertEncoderType\n",
    "from health_multimodal.image import get_image_inference\n",
    "from health_multimodal.image.utils import ImageModelType\n",
    "from health_multimodal.vlp import ImageTextInferenceEngine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3ad59df5-a66b-4fd8-aef3-2a696b296d5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A new version of the following files was downloaded from https://huggingface.co/microsoft/BiomedVLP-BioViL-T:\n",
      "- modeling_cxrbert.py\n",
      ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "The model class you are passing has a `config_class` attribute that is not consistent with the config class you passed (model has <class 'transformers_modules.microsoft.BiomedVLP-BioViL-T.301f526e823b805d3fe712d0cf06a66f042789c5.configuration_cxrbert.CXRBertConfig'> and you passed <class 'transformers.models.bert.configuration_bert.BertConfig'>. Fix one of those so they match!",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m url \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmicrosoft/BiomedVLP-BioViL-T\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      6\u001b[0m tokenizer \u001b[38;5;241m=\u001b[39m AutoTokenizer\u001b[38;5;241m.\u001b[39mfrom_pretrained(url, trust_remote_code\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m----> 7\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mAutoModel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrust_remote_code\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# # Input text prompts describing findings.\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# # The order of prompts is adjusted to capture the spectrum from absence of a finding to its temporal progression.\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# text_prompts = [\"No pleural effusion or pneumothorax is seen.\",\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;66;03m#     # Compute the cosine similarity of sentence embeddings obtained from input text prompts.\u001b[39;00m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;66;03m#     sim = torch.mm(embeddings, embeddings.t())\u001b[39;00m\n",
      "File \u001b[0;32m~/cxr-generation/notebooks/diffedit_diffusers/lib/python3.9/site-packages/transformers/models/auto/auto_factory.py:560\u001b[0m, in \u001b[0;36m_BaseAutoModelClass.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m    558\u001b[0m         model_class\u001b[38;5;241m.\u001b[39mregister_for_auto_class(\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m)\n\u001b[1;32m    559\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 560\u001b[0m         \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mregister\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;18;43m__class__\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_class\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexist_ok\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    561\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m model_class\u001b[38;5;241m.\u001b[39mfrom_pretrained(\n\u001b[1;32m    562\u001b[0m         pretrained_model_name_or_path, \u001b[38;5;241m*\u001b[39mmodel_args, config\u001b[38;5;241m=\u001b[39mconfig, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mhub_kwargs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[1;32m    563\u001b[0m     )\n\u001b[1;32m    564\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(config) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping\u001b[38;5;241m.\u001b[39mkeys():\n",
      "File \u001b[0;32m~/cxr-generation/notebooks/diffedit_diffusers/lib/python3.9/site-packages/transformers/models/auto/auto_factory.py:586\u001b[0m, in \u001b[0;36m_BaseAutoModelClass.register\u001b[0;34m(cls, config_class, model_class, exist_ok)\u001b[0m\n\u001b[1;32m    576\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    577\u001b[0m \u001b[38;5;124;03mRegister a new model for this class.\u001b[39;00m\n\u001b[1;32m    578\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    583\u001b[0m \u001b[38;5;124;03m        The model to register.\u001b[39;00m\n\u001b[1;32m    584\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    585\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(model_class, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconfig_class\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m model_class\u001b[38;5;241m.\u001b[39mconfig_class \u001b[38;5;241m!=\u001b[39m config_class:\n\u001b[0;32m--> 586\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    587\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe model class you are passing has a `config_class` attribute that is not consistent with the \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    588\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconfig class you passed (model has \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_class\u001b[38;5;241m.\u001b[39mconfig_class\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m and you passed \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfig_class\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. Fix \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    589\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mone of those so they match!\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    590\u001b[0m     )\n\u001b[1;32m    591\u001b[0m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping\u001b[38;5;241m.\u001b[39mregister(config_class, model_class, exist_ok\u001b[38;5;241m=\u001b[39mexist_ok)\n",
      "\u001b[0;31mValueError\u001b[0m: The model class you are passing has a `config_class` attribute that is not consistent with the config class you passed (model has <class 'transformers_modules.microsoft.BiomedVLP-BioViL-T.301f526e823b805d3fe712d0cf06a66f042789c5.configuration_cxrbert.CXRBertConfig'> and you passed <class 'transformers.models.bert.configuration_bert.BertConfig'>. Fix one of those so they match!"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "\n",
    "# Load the model and tokenizer\n",
    "url = \"microsoft/BiomedVLP-BioViL-T\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(url, trust_remote_code=True)\n",
    "model = AutoModel.from_pretrained(url, trust_remote_code=True)\n",
    "\n",
    "# # Input text prompts describing findings.\n",
    "# # The order of prompts is adjusted to capture the spectrum from absence of a finding to its temporal progression.\n",
    "# text_prompts = [\"No pleural effusion or pneumothorax is seen.\",\n",
    "#                 \"There is no pneumothorax or pleural effusion.\",\n",
    "#                 \"The extent of the pleural effusion is reduced.\",\n",
    "#                 \"The extent of the pleural effusion remains constant.\",\n",
    "#                 \"Interval enlargement of pleural effusion.\"]\n",
    "\n",
    "# # Tokenize and compute the sentence embeddings\n",
    "# with torch.no_grad():\n",
    "#     tokenizer_output = tokenizer.batch_encode_plus(batch_text_or_text_pairs=text_prompts,\n",
    "#                                                    add_special_tokens=True,\n",
    "#                                                    padding='longest',\n",
    "#                                                    return_tensors='pt')\n",
    "#     embeddings = model.get_projected_text_embeddings(input_ids=tokenizer_output.input_ids,\n",
    "#                                                  attention_mask=tokenizer_output.attention_mask)\n",
    "\n",
    "#     # Compute the cosine similarity of sentence embeddings obtained from input text prompts.\n",
    "#     sim = torch.mm(embeddings, embeddings.t())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9197600d-406e-4ef6-afbc-5771200de935",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3358d000-3900-4b88-81bd-94f8df223137",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
