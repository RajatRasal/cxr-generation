{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9faeef27-591e-4f82-99ca-8abb0b7b561f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/vol/biomedic3/rrr2417/cxr-generation/notebooks/diffedit_diffusers/lib/python3.9/site-packages/transformers/utils/hub.py:123: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from prompt_to_prompt.ptp_utils import load_512\n",
    "from prompt_to_prompt.null_text_inversion_batched import NullTextInversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "65b0c21d-0874-4ddf-bafc-ba090ad24e6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from diffusers import StableDiffusionPipeline, DDIMScheduler\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "random.seed(8888)\n",
    "generator_cuda = torch.Generator(\"cuda:0\").manual_seed(8888)\n",
    "generator_cpu = torch.Generator().manual_seed(8888)\n",
    "torch_dtype = torch.float32\n",
    "device = torch.device('cuda:0') if torch.cuda.is_available() else torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c3eecd0b-79de-479c-b057-4f9f24bfa4f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_DIFFUSION_STEPS = 50\n",
    "GUIDANCE_SCALE = 7.5\n",
    "MAX_NUM_WORDS = 77\n",
    "LOW_RESOURCE = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ab932921-897f-4550-80b1-998e496a99e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.datasets import OxfordIIITPet\n",
    "ds = OxfordIIITPet(root=\".\", split=\"trainval\", download=True)\n",
    "# image = load_512(np.array(ds[0][0]))\n",
    "image = load_512(np.array(Image.open(\"milo.jpeg\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5ce8e866-111f-4a49-9b64-bafafd54f4f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "vowels = \"aeiou\"\n",
    "classes = [_class.lower() for _class in ds.class_to_idx.keys()]\n",
    "class_strings = [f\"{'an' if _class[0] in vowels else 'a'} {_class}\" for _class in classes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "04a98336-ace9-4572-90e1-27c3f6214f84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3545ebc2e71e4a4ea07221d128b73bde",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading pipeline components...:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You have disabled the safety checker for <class 'diffusers.pipelines.stable_diffusion.pipeline_stable_diffusion.StableDiffusionPipeline'> by passing `safety_checker=None`. Ensure that you abide to the conditions of the Stable Diffusion license and do not expose unfiltered results in services or applications open to the public. Both the diffusers team and Hugging Face strongly recommend to keep the safety filter enabled in all public facing circumstances, disabling it only for use-cases that involve analyzing network behavior or auditing its results. For more information, please have a look at https://github.com/huggingface/diffusers/pull/254 .\n"
     ]
    }
   ],
   "source": [
    "model_path = \"runwayml/stable-diffusion-v1-5\"\n",
    "model = StableDiffusionPipeline.from_pretrained(\n",
    "    model_path,\n",
    "    torch_dtype=torch_dtype,\n",
    "    safety_checker=None,\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2749ffe5-598f-4e28-a8fd-ffa39b4b0518",
   "metadata": {},
   "source": [
    "## Load MS COCO annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "01f8029c-4029-4fd8-8cdf-eb8001995b93",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "val_captions = \"captions_train2017.json\"\n",
    "\n",
    "with open(val_captions, \"r\") as f:\n",
    "    captions_train = json.load(f)\n",
    "\n",
    "annotations = captions_train[\"annotations\"]\n",
    "images = captions_train[\"images\"]\n",
    "\n",
    "annotation_embeddings_index = torch.load(\"annotation_embeddings_index\").cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "564f3535-1ce2-41ad-9362-b0c337553614",
   "metadata": {},
   "source": [
    "## Null-text Inversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7af2450e-8d17-4938-a14b-8629f342e243",
   "metadata": {},
   "outputs": [],
   "source": [
    "nti = NullTextInversion(model, NUM_DIFFUSION_STEPS, GUIDANCE_SCALE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b526e9b1-38ef-41cc-a515-10f47419ae9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_size = 100\n",
    "ds_indexes = random.sample(range(len(ds)), dataset_size)\n",
    "images = [np.array(ds[i][0]) for i in ds_indexes]\n",
    "prompts = [f\"a photo of {class_strings[ds[i][1]]}\" for i in ds_indexes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d91f7c32-0739-4cb4-9280-1541e671d698",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                     | 0/100 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "null_embeddings = nti.fit(images, prompts, max_steps=100, num_inner_steps=1, lr_scale_factor=1e-2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5739d8d0-718e-4400-ac23-a165913c0c22",
   "metadata": {},
   "source": [
    "## Interpreting Optimised Latents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf90a618-1b6d-40af-a800-c334efb0eae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "seed = 50\n",
    "pca = PCA(n_components=7, random_state=seed)\n",
    "annotation_embeddings_index_proj = pca.fit_transform(annotation_embeddings_index.cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b22869e7-2179-44c6-9524-afb51059507e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "def interpret_aligned_latents(embeddings_list):\n",
    "    idxs = [0, 10, 20, 30, 40, 49]\n",
    "    for idx in idxs:\n",
    "        mean_embedding = embeddings_list[idx].cpu().numpy().mean(axis=1)\n",
    "        cond_embedding = pca.transform(mean_embedding)\n",
    "        min_index = np.argmax(cosine_similarity(annotation_embeddings_index_proj, cond_embedding))\n",
    "        annotation = annotations[int(min_index)]\n",
    "        print(idx, annotation[\"caption\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee7113e4-0190-40f3-b01d-0cbe54d89030",
   "metadata": {},
   "outputs": [],
   "source": [
    "interpret_aligned_latents(null_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08f39b1f-eec0-4dae-b328-c4686a3c0726",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
